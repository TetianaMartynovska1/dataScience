{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green>\n",
    "\n",
    "# Linear Regression: Ridge, Lasso, Normal Equation, Polynomial\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Set interactive backend \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Load boston data set \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(features= None, verbose= False):\n",
    "    X, y = load_diabetes(return_X_y=True)\n",
    "\n",
    "    if features is None:\n",
    "        print ('Selecting all features')\n",
    "        \n",
    "    elif type(features) == int or (type(features) == list and len(features)==1):\n",
    "        print ('Selecting one feature: {}'.format(features))\n",
    "        X= X[:,features].reshape(-1,1) # single column \n",
    "    elif type(features) == list: \n",
    "        print ('Selecting features list: {}'.format(features))\n",
    "        X= X[:,features]\n",
    "    else: \n",
    "        print ('wrong format of parameter \"features\"')\n",
    "        return\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test=  train_test_split(X, y, random_state=2021)\n",
    "    if verbose:\n",
    "        print ('X_train.shape= ',X_train.shape)\n",
    "        print ('y_train.shape= ',y_train.shape)\n",
    "        print ('X_train [:5] = \\n{}'.format(X_train[:5]))\n",
    "        print ('y_train [:5] = \\n{}'.format(y_train[:5]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "y_train.shape=  (331,)\n",
      "X_train [:5] = \n",
      "[[-0.06363517 -0.04464164 -0.03315126 -0.03321323  0.00118295  0.02405115\n",
      "  -0.02499266 -0.00259226 -0.02251653 -0.05906719]\n",
      " [ 0.01264814 -0.04464164 -0.02560657 -0.04009893 -0.03046397 -0.04515466\n",
      "   0.0780932  -0.0763945  -0.07213275  0.01134862]\n",
      " [ 0.03807591  0.05068012  0.00888341  0.04252949 -0.04284755 -0.02104223\n",
      "  -0.03971921 -0.00259226 -0.01811369  0.00720652]\n",
      " [-0.07816532  0.05068012  0.07786339  0.05285804  0.07823631  0.0644473\n",
      "   0.02655027 -0.00259226  0.04067283 -0.00936191]\n",
      " [-0.07453279 -0.04464164 -0.0105172  -0.00567042 -0.06623874 -0.0570543\n",
      "  -0.00290283 -0.03949338 -0.04257085 -0.0010777 ]]\n",
      "y_train [:5] = \n",
      "[214.  98. 127. 233. 168.]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y(verbose= True)\n",
    "# X_train, X_test, y_train, y_test=  get_X_y([5],verbose= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Linear Regression\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "R2 train score = 0.5073693366380002\n",
      "R2 test score = 0.5281729599217633\n",
      "b: 148.99290898243794, \n",
      "w= [ -19.6849459  -240.17712443  557.92071086  251.49875073 -500.35528341\n",
      "  275.55002947  -11.62872458  154.0055582   651.15320811   77.51418657]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "regressor = lin_reg\n",
    "print ('Linear Regression')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Ridge\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "R2 train score = 0.4227491733930173\n",
      "R2 test score = 0.4342973225973642\n",
      "b: 148.99989270370446, \n",
      "w= [  31.07148535  -67.8120157   284.12144626  158.3077359    25.34329106\n",
      "  -14.63150099 -130.28719404  116.41304414  239.50188481  108.52469397]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg=Ridge()\n",
    "ridge_reg.fit(X_train,y_train)\n",
    "regressor = ridge_reg\n",
    "print ('Ridge')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Lasso\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "R2 train score = 0.36601908968194896\n",
      "R2 test score = 0.33920924807921515\n",
      "b: 149.48529539341314, \n",
      "w= [  0.          -0.         379.30812187   0.           0.\n",
      "   0.          -0.           0.         317.42349078   0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg=Lasso()\n",
    "lasso_reg.fit(X_train,y_train)\n",
    "regressor = lasso_reg\n",
    "print ('Lasso')\n",
    "print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Comparing to KNN\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "KNN\n",
      "n_neighbors=1\n",
      "R2 train score = 1.0\n",
      "R2 test score = -0.09095569737227827\n",
      "n_neighbors=2\n",
      "R2 train score = 0.75205211713433\n",
      "R2 test score = 0.17016447278513447\n",
      "n_neighbors=3\n",
      "R2 train score = 0.6758033181412969\n",
      "R2 test score = 0.2381809619257087\n",
      "n_neighbors=4\n",
      "R2 train score = 0.6155525801130263\n",
      "R2 test score = 0.27733360958680453\n",
      "n_neighbors=5\n",
      "R2 train score = 0.5971693804267382\n",
      "R2 test score = 0.3284875313602935\n",
      "n_neighbors=6\n",
      "R2 train score = 0.5798068060304129\n",
      "R2 test score = 0.34198004354416\n",
      "n_neighbors=7\n",
      "R2 train score = 0.5774888738145572\n",
      "R2 test score = 0.34425865483160567\n",
      "n_neighbors=8\n",
      "R2 train score = 0.5672443132619438\n",
      "R2 test score = 0.3729549962651513\n",
      "n_neighbors=9\n",
      "R2 train score = 0.5641246455859588\n",
      "R2 test score = 0.36825966395622667\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y()\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "print ('KNN')\n",
    "for n_neighbors in range(1,10):\n",
    "    regressor = KNeighborsRegressor(n_neighbors=n_neighbors).fit (X_train,y_train)\n",
    "    print ('n_neighbors={}'.format (n_neighbors))\n",
    "    print ('R2 train score =', regressor.score(X_train, y_train))\n",
    "    print ('R2 test score =', regressor.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Normal Equation\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "Solving linear regression using normal equation...\n",
      "b: 148.99290898243888, \n",
      "w= [[ -19.6849459  -240.17712443  557.92071086  251.49875073 -500.35528341\n",
      "   275.55002947  -11.62872458  154.0055582   651.15320811   77.51418657]]\n",
      "Predicting using normal equation...\n",
      "R2 train score = 0.5073693366380001\n",
      "R2 test score = 0.5281729599217677\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y()\n",
    "m,n = X_train.shape\n",
    "# adding 1-column\n",
    "X_train_ext =  np.c_[(np.ones((m,1)),X_train)]\n",
    "assert (X_train_ext.shape== (m,n+1))\n",
    "\n",
    "print ('Solving linear regression using normal equation...')\n",
    "\n",
    "params = np.linalg.pinv (X_train_ext.T @ X_train_ext ) @ X_train_ext.T @ y_train\n",
    "\n",
    "\n",
    "params = np.linalg.pinv (X_train_ext.T @ X_train_ext ) @ X_train_ext.T @ y_train\n",
    "b = params[0]\n",
    "w=params[1:].reshape (1,-1) \n",
    "print ('b: {}, \\nw= {}'.format(b,w)) \n",
    "\n",
    "print ('Predicting using normal equation...')\n",
    "\n",
    "z_train= b+ X_train @ w.T\n",
    "z_test= b+ X_test @ w.T\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print ('R2 train score =',  r2_score(y_train,z_train))\n",
    "print ('R2 test score =', r2_score(y_test,z_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Polynomial\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Polynomial + Linear Regression\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 65)\n",
      "Polynomial + Linear Regression\n",
      "R2 train score = 0.6207810962295993\n",
      "R2 test score = 0.34722439867190236\n",
      "b: 55.745642090171586, \n",
      "w= [ 1.06137498e+02 -2.77244219e+02  5.11354358e+02  2.51478306e+02\n",
      " -1.82518302e+04  1.59323845e+04  6.66445690e+03  1.74014774e+02\n",
      "  6.57536398e+03  9.66610282e+01  2.78325334e+03  3.85281468e+03\n",
      " -1.53395915e+02  9.33380694e+02  7.84255464e+03 -1.10762461e+04\n",
      " -1.11174456e+03  2.01277652e+03  1.35040875e+03 -1.10327017e+03\n",
      " -1.67413429e+00  2.29828166e+03  2.55277891e+02 -6.62033960e+02\n",
      "  1.81130613e+03  1.37538779e+02 -6.93403727e+03  1.68439720e+03\n",
      "  1.60179356e+03  1.15224299e+03  3.13930733e+03 -8.23706391e+02\n",
      "  6.06446052e+02  9.05587243e+02 -1.25957240e+03  3.92326702e+02\n",
      "  7.84474860e+02 -3.72762355e+02  1.50641940e+04 -1.23251806e+04\n",
      " -3.94541792e+03  3.05725415e+03 -5.21151753e+03 -2.22762962e+03\n",
      "  8.83280542e+04 -1.14624080e+05 -7.24321258e+04 -3.63921143e+04\n",
      " -2.64089121e+04 -4.87133850e+03  3.72219511e+04  4.48634626e+04\n",
      "  2.00114668e+04  1.20913439e+04  9.24913877e+02  1.31372359e+04\n",
      "  9.59115876e+03  1.12090903e+04  1.07482695e+04  3.89815589e+03\n",
      "  9.14000032e+03  8.77867792e+03  2.96364287e+04  3.13815886e+03\n",
      "  1.70557446e+03]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y()\n",
    "\n",
    "poly= PolynomialFeatures(degree=2,include_bias=False)\n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "# X_train_poly[:5]\n",
    "poly_lin_reg = LinearRegression().fit (X_train_poly,y_train)\n",
    "regressor = poly_lin_reg\n",
    "print ('Polynomial + Linear Regression')\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: the R2 scores on training and test  show it is overfitting\n",
    "Though it is better that w/o poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 65)\n",
      "Polynomial + Normalization + Linear Regression\n",
      "R2 train score = 0.6186800817374429\n",
      "R2 test score = 0.3567788640015631\n",
      "b: 133.4063452967691, \n",
      "w= [ 4.97209636e+00  3.88562348e+14  2.49072149e+01  1.16213097e+01\n",
      " -8.73121834e+02  7.64096681e+02  3.07384169e+02  1.22193351e+01\n",
      "  3.15778767e+02  3.94531250e+00  6.37500000e+00  7.76562500e+00\n",
      " -3.82812500e-01  1.81250000e+00  1.31875000e+01 -2.00937500e+01\n",
      " -7.85156250e-01  5.37500000e+00  4.32812500e+00 -2.74218750e+00\n",
      " -3.88562348e+14  4.54882812e+00  1.10937500e+00  3.06054688e+00\n",
      "  9.45312500e-01 -8.98437500e-01 -1.55390625e+01  3.72265625e+00\n",
      "  2.80566406e+00  4.73437500e+00  6.14062500e+00 -2.04687500e+00\n",
      "  3.45312500e+00  1.02343750e+00 -5.94140625e+00  2.01562500e+00\n",
      "  2.03906250e+00  4.06250000e-01  2.55781250e+01 -2.06093750e+01\n",
      " -7.20703125e+00  6.06054688e+00 -1.00996094e+01 -4.67187500e+00\n",
      "  2.98390625e+02 -4.00804688e+02 -1.51332031e+02 -9.88281250e+01\n",
      " -5.90937500e+01 -9.59375000e+00  1.43867188e+02  8.91250000e+01\n",
      "  6.05859375e+01  2.62500000e+01 -6.09375000e-01  3.96250000e+01\n",
      "  2.29453125e+01  2.51640625e+01  2.38671875e+01  1.50244141e+01\n",
      "  2.27617188e+01  2.41328125e+01  9.57880859e+01  7.72265625e+00\n",
      "  5.58203125e+00]\n"
     ]
    }
   ],
   "source": [
    "# Try with normalization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test=  get_X_y(verbose= False)\n",
    "\n",
    "poly= PolynomialFeatures(degree=2,include_bias=False)  \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "\n",
    "scaler= StandardScaler()\n",
    "X_train_poly_scaled = scaler.fit_transform(X_train_poly)\n",
    "X_test_poly_scaled= scaler.transform(X_test_poly)\n",
    "# X_train_poly[:5]\n",
    "poly_lin_reg = LinearRegression().fit (X_train_poly_scaled,y_train)\n",
    "regressor = poly_lin_reg\n",
    "print ('Polynomial + Normalization + Linear Regression')\n",
    "print ('R2 train score =', regressor.score(X_train_poly_scaled, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly_scaled, y_test))\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, regressor.coef_)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Polynomial + Ridge\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 65)\n",
      "Polynomial + Ridge\n",
      "R2 train score = 2.1609200691052877e-06\n",
      "R2 test score = -0.013170793147653903\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y(verbose= False)\n",
    "\n",
    "poly= PolynomialFeatures(degree=2,include_bias=False) \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "\n",
    "poly_ridge = Ridge(alpha=1e6, max_iter=100000).fit(X_train_poly, y_train)\n",
    "regressor = poly_ridge\n",
    "print ('Polynomial + Ridge')\n",
    "\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "w= regressor.coef_\n",
    "# print ('b: {}, \\nw= {}'.format(regressor.intercept_, w)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Try polynomial degree = 3 for Ridge \n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 285)\n",
      "Polynomial + Ridge\n",
      "R2 train score = 4.322475710694107e-11\n",
      "R2 test score = -0.01317309394302435\n"
     ]
    }
   ],
   "source": [
    "poly= PolynomialFeatures(degree=3,include_bias=False) # default is True means to return the first feature of all 1 as for degree 0 \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "\n",
    "poly_ridge = Ridge(alpha=5e10, max_iter=100000).fit (X_train_poly,y_train)\n",
    "regressor = poly_ridge\n",
    "print ('Polynomial + Ridge')\n",
    "\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "w= regressor.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Polynomial + Lasso\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting all features\n",
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 285)\n",
      "Polynomial + Lasso\n",
      "R2 train score = 0.36601908968194896\n",
      "R2 test score = 0.33920924807921515\n",
      "b: 149.48529539341314, \n",
      "w= [  0.          -0.         379.30812187   0.           0.\n",
      "   0.          -0.           0.         317.42349078   0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "  -0.          -0.           0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "   0.           0.          -0.          -0.          -0.\n",
      "  -0.           0.          -0.          -0.           0.\n",
      "   0.          -0.           0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "   0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "   0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.          -0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "  -0.          -0.          -0.           0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "   0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "   0.           0.          -0.           0.          -0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "  -0.          -0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.          -0.          -0.          -0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.          -0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.          -0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "  -0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.          -0.          -0.           0.           0.\n",
      "   0.          -0.          -0.          -0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -0.           0.           0.           0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.        ]\n",
      "\n",
      "Relevant w= [379.30812187 317.42349078]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test=  get_X_y(verbose= False)\n",
    "\n",
    "poly= PolynomialFeatures(degree=3,include_bias=False) # default is True means to return the first feature of all 1 as for degree 0 \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "\n",
    "poly_lasso = Lasso(max_iter=100000).fit (X_train_poly,y_train)\n",
    "regressor = poly_lasso\n",
    "print ('Polynomial + Lasso')\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "\n",
    "w= regressor.coef_\n",
    "print ('b: {}, \\nw= {}'.format(regressor.intercept_, w)) \n",
    "w_relevant= w[np.abs(w) > 1e-2]\n",
    "print ('\\nRelevant w= {}'.format(w_relevant)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "#### Try polynomial degree = 3  for Lasso\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape=  (331, 10)\n",
      "X_train_poly.shape=  (331, 285)\n",
      "Polynomial + Lasso\n",
      "R2 train score = 0.0\n",
      "R2 test score = -0.01317309398904798\n",
      "\n",
      "Relevant w= []\n"
     ]
    }
   ],
   "source": [
    "poly= PolynomialFeatures(degree=3,include_bias=False) \n",
    "X_train_poly= poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "print ('X_train.shape= ',X_train.shape)\n",
    "print ('X_train_poly.shape= ',X_train_poly.shape)\n",
    "\n",
    "poly_lasso = Lasso(alpha= 10, max_iter=1000000).fit (X_train_poly,y_train)\n",
    "regressor = poly_lasso\n",
    "print ('Polynomial + Lasso')\n",
    "print ('R2 train score =', regressor.score(X_train_poly, y_train))\n",
    "print ('R2 test score =', regressor.score(X_test_poly, y_test))\n",
    "\n",
    "w= regressor.coef_\n",
    "w_relevant= w[np.abs(w) > 1e-2]\n",
    "print ('\\nRelevant w= {}'.format(w_relevant)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
